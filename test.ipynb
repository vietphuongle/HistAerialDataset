{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4-QdnXElyLE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a7d6a0f-2c1d-47e6-a074-1aa3112b21fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras import layers, models\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "80MbXEqUl2W_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your dataset and batch size\n",
        "data_path = '/content/drive/MyDrive/data1/100x100_overlap_0percent'\n",
        "train_data_file = data_path + '/' + 'train6k.txt'\n",
        "val_data_file = data_path + \"/\" + \"val6k.txt\"\n",
        "test_data_file = data_path + \"/\" + \"test6k.txt\"\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "FnblJe-wl4wF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data using pandas\n",
        "train_df = pd.read_csv(train_data_file, delimiter=' ', header=None)\n",
        "val_df = pd.read_csv(val_data_file, delimiter=' ', header=None)\n",
        "test_df = pd.read_csv(test_data_file, delimiter=' ', header=None)\n",
        "\n",
        "# Convert the labels to strings\n",
        "train_df[1] = train_df[1].astype(str)\n",
        "val_df[1] = val_df[1].astype(str)\n",
        "test_df[1] = test_df[1].astype(str)\n",
        "\n",
        "# Add the pre-path to the file paths\n",
        "train_df[0] = data_path +'/'+ train_df[0]\n",
        "val_df[0] = data_path +'/'+ val_df[0]\n",
        "test_df[0] = data_path +'/'+ test_df[0]\n",
        "\n",
        "# Split the data to use 10% for experiment\n",
        "train_df, _ = train_test_split(train_df, test_size=0.90, random_state=42)\n",
        "val_df, _ = train_test_split(val_df, test_size=0.90, random_state=42)\n",
        "test_df, _ = train_test_split(test_df, test_size=0.90, random_state=42)\n",
        "\n",
        "# Create data generators for training, validation, and test datasets\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col=0,\n",
        "    y_col=1,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col=0,\n",
        "    y_col=1,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col=0,\n",
        "    y_col=1,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "3Z-lClbSoREN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each class in the train, test, and val datasets\n",
        "train_class_counts = train_df[1].value_counts()\n",
        "test_class_counts = test_df[1].value_counts()\n",
        "val_class_counts = val_df[1].value_counts()\n",
        "\n",
        "# Get unique class labels\n",
        "unique_labels = train_df[1].unique()\n",
        "\n",
        "# Create subplots for train, test, and val histograms\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(131)\n",
        "plt.bar(unique_labels, train_class_counts)\n",
        "plt.title('Train Dataset Class Distribution')\n",
        "plt.xlabel('Class Label')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.subplot(132)\n",
        "plt.bar(unique_labels, test_class_counts)\n",
        "plt.title('Test Dataset Class Distribution')\n",
        "plt.xlabel('Class Label')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.subplot(133)\n",
        "plt.bar(unique_labels, val_class_counts)\n",
        "plt.title('Validation Dataset Class Distribution')\n",
        "plt.xlabel('Class Label')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WsAe3_MpF1Fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the convolutional layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(7, activation='softmax')  # 7 output classes\n",
        "])"
      ],
      "metadata": {
        "id": "OErRgmlwo_g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show model\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "zuouK_q8o7GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "epochs = 5\n",
        "history = model.fit(train_generator,\n",
        "                    validation_data=val_generator,\n",
        "                    epochs=epochs)\n",
        "model.save(data_path + '/' + 'savemodel.h5')"
      ],
      "metadata": {
        "id": "32BGspK9pFQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and Accuracy over Epochs\n",
        "training_loss = history.history['loss']\n",
        "training_accuracy = history.history['accuracy']\n",
        "validation_loss = history.history['val_loss']\n",
        "validation_accuracy = history.history['val_accuracy']\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(training_loss, label='Training Loss')\n",
        "plt.plot(validation_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(training_accuracy, label='Training Accuracy')\n",
        "plt.plot(validation_accuracy, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5i7cTQ94OSuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test loss and Test accuracy\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "wsdUf3AOpsOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the confusion matrix\n",
        "test_generator.reset()\n",
        "\n",
        "y_true = test_generator.classes\n",
        "y_pred = model.predict(test_generator)\n",
        "\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,\n",
        "                              display_labels=test_generator.class_indices.keys())\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "disp.plot(cmap='Blues', values_format='d')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tYMTw-5iczZF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}